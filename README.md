#  Replication Package for: Robust Machine Learning Algorithms for Text Analysis

[![Dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://kacperkrasowski.github.io/KeMontielOleaNesbit2024.jl/dev/)
[![Build Status](https://github.com/kacperkrasowski/KeMontielOleaNesbit2024.jl/actions/workflows/docs.yml/badge.svg?branch=main)](https://github.com/kacperkrasowski/KeMontielOleaNesbit2024.jl/actions/workflows/docs.yml)



This repository is dedicated for a replication package of Ke, Shikun, José Luis Montiel Olea, and James Nesbit. "Robust Machine Learning Algorithms for Text Analysis." Quantitative Economics, 15, .no 4, (Econometric Society: 2024), 939-970. https://doi.org/10.3982/QE1825. The original code was written in Matlab and Python and was translated by us to Julia.

LINK TO FLORIAN WEBSITE
<!---
Include as much detail in the article citation as you can.
-->

## Authors 

- Kacper Krasowski
- Stefano Fusinatio

<!---
The replication package can have a different set of authors than the article.
-->

# Data availability and provenance statements

### Summary of availability

- This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code). 

### Details on data source

<!---
rework the relevant examples from below
-->


- The pdf FOMC transcripts was dowloaded from a [Dropbox](https://www.dropbox.com/scl/fo/tdtyskrt9t0eiumoru6ng/h?rlkey=k05l6qtmq8m4n6ot5gtqtyuos&dl=0) provided by the Authors of the paper. 
- Rest of the data authors obtained from Hansen, Stephen & McMahon, Michael & Prat, Andrea. (2018). "Transparency and Deliberation Within the FOMC: A Computational Linguistics Approach". Quarterly Journal of Economics. 133. 801-870. 10.1093/qje/qjx045. The data includes the transparency indicator and the names of the members of FOMC meetings. 


# Computational requirements

<!---
In general, the specific computer code used to generate the results in the article will be within the repository that also contains this README. However, other computational requirements - shared libraries or code packages, required software, specific computing hardware - may be important, and is always useful, for the goal of replication. Some example text follows. 
-->
### Software requirements

<!---
List all of the software requirements, up to and including any operating system requirements, for the entire set of code. It is suggested to distribute most dependencies together with the replication package if allowed, in particular if sourced from unversioned code repositories, Github repos, and personal webpages. In all cases, list the version *you* used. 
-->

- Julia (1.11.3) 
  - CSV (0.10.15)  
  - DataFrames (1.7.0)  
  - DataStructures (0.18.22)  
  - Distributions (0.25.120)  
  - JLD2 (0.5.13)  
  - JSON (0.21.4)  
  - KernelDensity (0.6.9)  
  - LaTeXStrings (1.4.0)  
  - LinearAlgebra (1.11.0)  
  - PDFIO (0.1.15)  
  - Plots (1.40.13)  
  - Random (1.11.0)  
  - SpecialFunctions (2.5.1)  
  - Statistics (1.11.1)  
  - StatsPlots (0.15.7)  
  - StopWords (1.0.1)  
  - Test (1.11.0)
  - TextAnalysis (0.8.2)  
  - WordCloud (1.3.2)  
  - XLSX (0.10.4)  


STUFF ABOUT FLATTENING

### Memory and runtime requirements
In order to run the replication one should have at least 50 GB of free storage in order to strore the results of Negative Matrix Factorization process.
<!---
Memory and compute-time requirements may also be relevant or even critical. Some example text follows. It may be useful to break this out by Table/Figure/section of processing. For instance, some estimation routines might run for weeks, but data prep and creating figures might only take a few minutes.
-->

#### Summary

The runtime depends on the eps parameter set in Main_generate_NMF_draws. Approximate time needed to reproduce the analyses on a standard 2025 desktop machine: 
- 5 hours for eps = 2-e4
- 10 hours for eps = 1-e4


#### Details
The code was last run on **4-core Intel-based laptop with Windows 11 version 23H2** with **16 GB RAM**.


# Dataset list

<!---
In some cases, authors will provide one dataset (file) per data source, and the code to combine them. In others, in particular when data access might be restrictive, the replication package may only include derived/analysis data. Every file should be described. This can be provided as a Excel/CSV table, or in the table below.
-->

| Data file | Source | Notes    |Provided |
|-----------|--------|----------|---------|
| `data/raw/FOMCdatemeeting.pfg.dta` | Authors | 148 transcripts | Yes |
| `data/utils/covariates.csv` | Authors | Covariates used in  Hansen, McMahon, and Prat (2018) | Yes |
| `data/utils/firstnames.xlsx`| Authors | Names of meetings members | Yes |
| `data/utils/stopwords_long.xlsx`| Authors | Long stop words | Yes |
| `data/utils/stopwords_short.xlsx`| Authors | Short stop words | Yes |
ADD THE CLEAN ONES

# List of tables and figures

<!---
Your programs should clearly identify the tables and figures as they appear in the manuscript, by number. Sometimes, this may be obvious, e.g. a program called "`table1.do`" generates a file called `table1.png`. Sometimes, mnemonics are used, and a mapping is necessary. In all circumstances, provide a list of tables and figures, identifying the program (and possibly the line number) where a figure is created.

If the public repository is incomplete, because not all data can be provided, as described in the data section, then the list of tables should clearly indicate which tables, figures, and in-text numbers can be reproduced with the public material provided.
-->

The provided code reproduces:
<!---
pick one
-->
- All figures in the paper


| Figure/Table #    | Program                  | Line Number | Output file                      | Note                            |
|-------------------|--------------------------|-------------|----------------------------------|---------------------------------|
| Table 1           | 02_analysis/table1.do    |             | summarystats.csv                 ||
| Table 2           | 02_analysis/table2and3.do| 15          | table2.csv                       ||
| Table 3           | 02_analysis/table2and3.do| 145         | table3.csv                       ||
| Figure 1          | n.a. (no data)           |             |                                  | Source: Herodus (2011)          |
| Figure 2          | 02_analysis/fig2.do      |             | figure2.png                      ||
| Figure 3          | 02_analysis/fig3.do      |             | figure-robustness.png            | Requires confidential data      |


# Instructions to replicators

<!---
The first two sections ensure that the data and software necessary to conduct the replication have been collected. This section then describes a human-readable instruction to conduct the replication. This may be simple, or may involve many complicated steps. It should be a simple list, no excess prose. Strict linear sequence. If more than 4-5 manual steps, please wrap a master program/Makefile around them, in logical sequences. Examples follow.
-->

- Edit `programs/config.do` to adjust the default path
- Run `programs/00_setup.do` once on a new system to set up the working environment. 
- Download the data files referenced above. Each should be stored in the prepared subdirectories of `data/`, in the format that you download them in. Do not unzip. Scripts are provided in each directory to download the public-use files. Confidential data files requested as part of your FSRDC project will appear in the `/data` folder. No further action is needed on the replicator's part.
- Run `programs/01_master.do` to run all steps in sequence.

### Details

- `programs/00_setup.do`: will create all output directories, install needed ado packages. 
   - If wishing to update the ado packages used by this archive, change the parameter `update_ado` to `yes`. However, this is not needed to successfully reproduce the manuscript tables. 
- `programs/01_dataprep`:  
   - These programs were last run at various times in 2018. 
   - Order does not matter, all programs can be run in parallel, if needed. 
   - A `programs/01_dataprep/master.do` will run them all in sequence, which should take about 2 hours.
- `programs/02_analysis/master.do`.
   - If running programs individually, note that ORDER IS IMPORTANT. 
   - The programs were last run top to bottom on July 4, 2019.
- `programs/03_appendix/master - appendix.do`. The programs were last run top to bottom on July 4, 2019.
- Figure 1: The figure can be reproduced using the data provided in the folder “2_data/data_map”, and ArcGIS Desktop (Version 10.7.1) by following these (manual) instructions:
  - Create a new map document in ArcGIS ArcMap, browse to the folder
“2_data/data_map” in the “Catalog”, with files  "provinceborders.shp", "lakes.shp", and "cities.shp".
  - Drop the files listed above onto the new map, creating three separate layers. Order them with "lakes" in the top layer and "cities" in the bottom layer.
  - Right-click on the cities file, in properties choose the variable "health"... (more details)


# Description of programs/code

<!---
Give a high-level overview of the program files and their purpose. Remove redundant/ obsolete files from the Replication archive.
-->

- Programs in `programs/ 01_dataprep` will extract and reformat all datasets referenced above. The file `programs/01_dataprep/master.do` will run them all.
- Programs in `programs/02_analysis` generate all tables and figures in the main body of the article. The program `programs/02_analysis/master.do` will run them all. Each program called from `master.do` identifies the table or figure it creates (e.g., `05_table5.do`).  Output files are called appropriate names (`table5.tex`, `figure12.png`) and should be easy to correlate with the manuscript.
- Programs in `programs/03_appendix` will generate all tables and figures  in the online appendix. The program `programs/03_appendix/master - appendix.do` will run them all. 
- Ado files have been stored in `programs/ado` and the `master.do` files set the ADO directories appropriately. 
- The program `programs/00_setup.do` will populate the `programs/ado` directory with updated ado packages, but for purposes of exact reproduction, this is not needed. The file `programs/00_setup.log` identifies the versions as they were last updated.
- The program `programs/config.do` contains parameters used by all programs, including a random seed. Note that the random seed is set once for each of the two sequences (in `02_analysis` and `03_appendix`). If running in any order other than the one outlined below, your results may differ.

### (Optional, but recommended) License for Code

The code is licensed under a MIT/BSD/GPL/Creative Commons license. See [LICENSE.txt](LICENSE.txt) for details.


# References

<!---
As in any scientific manuscript, you should have proper references. For instance, in this sample README, we cited "Ruggles et al, 2019" and "DESE, 2019" in a Data Availability Statement. The reference should thus be listed here, in the style of your journal.
-->

- Steven Ruggles, Steven M. Manson, Tracy A. Kugler, David A. Haynes II, David C. Van Riper, and Maryia Bakhtsiyarava. 2018. "IPUMS Terra: Integrated Data on Population and Environment: Version 2 [dataset]." Minneapolis, MN: *Minnesota Population Center, IPUMS*. https://doi.org/10.18128/D090.V2
- Department of Elementary and Secondary Education (DESE), 2019. "Student outcomes database [dataset]" *Massachusetts Department of Elementary and Secondary Education (DESE)*. Accessed January 15, 2019.
- U.S. Bureau of Economic Analysis (BEA). 2016. “Table 30: "Economic Profile by County, 1969-2016.” (accessed Sept 1, 2017).
- Inglehart, R., C. Haerpfer, A. Moreno, C. Welzel, K. Kizilova, J. Diez-Medrano, M. Lagos, P. Norris, E. Ponarin & B. Puranen et al. (eds.). 2014. World Values Survey: Round Six - Country-Pooled Datafile Version: http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp. Madrid: JD Systems Institute.


## License

[MIT](https://choosealicense.com/licenses/mit/)